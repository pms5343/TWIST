{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: torch.Size([1, 10, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ----------------- Fusion Module 정의 -----------------\n",
    "class FusionBlock(nn.Module):\n",
    "    def __init__(self, sam2_in_channels, yolo_channels, fusion_method='concat'):\n",
    "        \"\"\"\n",
    "        sam2_in_channels: SAM2 feature의 채널 수\n",
    "        yolo_channels: YOLO feature의 채널 수 (fusion 후 목표 채널 수)\n",
    "        fusion_method: 'add' 또는 'concat'\n",
    "                         여기서는 'concat' 방식을 사용\n",
    "        \"\"\"\n",
    "        super(FusionBlock, self).__init__()\n",
    "        self.fusion_method = fusion_method\n",
    "        # SAM2 feature의 채널 수를 YOLO feature와 맞추기 위한 1x1 Conv\n",
    "        self.adapter = nn.Conv2d(sam2_in_channels, yolo_channels, kernel_size=1)\n",
    "        if self.fusion_method == 'concat':\n",
    "            # Concatenation 후 채널 수 축소를 위한 1x1 Conv\n",
    "            self.fusion_conv = nn.Conv2d(yolo_channels * 2, yolo_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, yolo_feat, sam2_feat):\n",
    "        \"\"\"\n",
    "        yolo_feat: YOLO의 feature map, shape: [B, C, H, W]\n",
    "        sam2_feat: SAM2의 feature map (채널 및 spatial 크기가 다를 수 있음)\n",
    "        \"\"\"\n",
    "        # 1x1 Conv를 통해 SAM2 feature의 채널 수를 맞춤\n",
    "        adapted_feat = self.adapter(sam2_feat)\n",
    "        # 만약 spatial 크기가 다르다면 YOLO feature의 크기에 맞게 조정\n",
    "        if adapted_feat.shape[-2:] != yolo_feat.shape[-2:]:\n",
    "            adapted_feat = F.interpolate(adapted_feat, size=yolo_feat.shape[-2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Concatenation 방식: 두 feature map을 채널 차원에서 이어 붙이고, fusion_conv로 채널 축소\n",
    "        if self.fusion_method == 'concat':\n",
    "            fused = torch.cat([yolo_feat, adapted_feat], dim=1)\n",
    "            fused = self.fusion_conv(fused)\n",
    "        elif self.fusion_method == 'add':\n",
    "            fused = yolo_feat + adapted_feat\n",
    "        else:\n",
    "            raise ValueError(\"fusion_method는 'add' 또는 'concat' 이어야 합니다.\")\n",
    "        return fused\n",
    "\n",
    "# 여러 scale에서 fusion을 동시에 수행하는 모듈\n",
    "class YOLOSAM2Fusion(nn.Module):\n",
    "    def __init__(self, fusion_configs, fusion_method='concat'):\n",
    "        \"\"\"\n",
    "        fusion_configs: 각 scale별 (SAM2 채널, YOLO 채널) 튜플 리스트\n",
    "                        예: [(32, 32), (64, 64), (256, 256)]\n",
    "        fusion_method: 'add' 또는 'concat'\n",
    "        \"\"\"\n",
    "        super(YOLOSAM2Fusion, self).__init__()\n",
    "        self.fusion_blocks = nn.ModuleList(\n",
    "            [FusionBlock(sam2_in, yolo_ch, fusion_method) for sam2_in, yolo_ch in fusion_configs]\n",
    "        )\n",
    "    \n",
    "    def forward(self, yolo_features, sam2_features):\n",
    "        \"\"\"\n",
    "        yolo_features: YOLO backbone에서 추출한 각 scale의 feature map 리스트\n",
    "        sam2_features: SAM2에서 추출한 각 scale의 feature map 리스트\n",
    "        두 리스트의 순서가 동일한 scale 순서임을 가정합니다.\n",
    "        \"\"\"\n",
    "        fused_features = []\n",
    "        for fusion_block, yolo_feat, sam2_feat in zip(self.fusion_blocks, yolo_features, sam2_features):\n",
    "            fused = fusion_block(yolo_feat, sam2_feat)\n",
    "            fused_features.append(fused)\n",
    "        return fused_features\n",
    "\n",
    "# ----------------- 더미 YOLO 모델 정의 (예시) -----------------\n",
    "# 실제로는 기존 YOLO 모델을 사용하지만, 여기서는 예시로 간단한 backbone과 detection head를 정의합니다.\n",
    "\n",
    "class DummyYOLOBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DummyYOLOBackbone, self).__init__()\n",
    "        # 예시로 3개의 convolution layer를 이용해 3개의 feature map 생성\n",
    "        self.layer1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)   # 예상 output: [B, 32, 128, 128]\n",
    "        self.layer2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 예상 output: [B, 64, 64, 64]\n",
    "        self.layer3 = nn.Conv2d(64, 256, kernel_size=3, padding=1) # 예상 output: [B, 256, 32, 32]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # layer1: feature map scale 0\n",
    "        x0 = F.relu(self.layer1(x))\n",
    "        # layer2: spatial downsampling을 위해 max pooling 후 feature map scale 1\n",
    "        x1 = F.relu(self.layer2(F.max_pool2d(x0, 2)))\n",
    "        # layer3: 다시 downsampling 후 feature map scale 2\n",
    "        x2 = F.relu(self.layer3(F.max_pool2d(x1, 2)))\n",
    "        # FPN과 유사하게 3개의 feature map을 반환\n",
    "        return [x0, x1, x2]\n",
    "\n",
    "class DummyYOLODetectionHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DummyYOLODetectionHead, self).__init__()\n",
    "        # detection head 예시: fused feature map에서 예측을 위한 1x1 Conv\n",
    "        self.conv = nn.Conv2d(256, 10, kernel_size=1)  # 예: 10개의 출력 채널\n",
    "    \n",
    "    def forward(self, fused_feature):\n",
    "        return self.conv(fused_feature)\n",
    "\n",
    "# ----------------- YOLO와 Fusion 모듈 통합 -----------------\n",
    "class YOLOWithFusion(nn.Module):\n",
    "    def __init__(self, fusion_module, yolo_backbone, detection_head):\n",
    "        \"\"\"\n",
    "        fusion_module: YOLOSAM2Fusion 모듈 (여기서는 concat 방식)\n",
    "        yolo_backbone: YOLO 모델의 backbone (FPN feature map 반환)\n",
    "        detection_head: YOLO의 detection head (fused feature map을 입력받음)\n",
    "        \"\"\"\n",
    "        super(YOLOWithFusion, self).__init__()\n",
    "        self.yolo_backbone = yolo_backbone\n",
    "        self.fusion_module = fusion_module\n",
    "        self.detection_head = detection_head\n",
    "    \n",
    "    def forward(self, x, sam2_features):\n",
    "        \"\"\"\n",
    "        x: 입력 이미지 tensor, shape: [B, 3, H, W]\n",
    "        sam2_features: SAM2의 backbone_fpn feature map 리스트 (각 scale별로 3개)\n",
    "        \"\"\"\n",
    "        # 1. YOLO backbone을 통해 FPN feature map 얻기\n",
    "        yolo_features = self.yolo_backbone(x)\n",
    "        \n",
    "        # 2. YOLO feature와 SAM2 feature를 fusion 모듈로 융합 (여기서 concat 방식 사용)\n",
    "        fused_features = self.fusion_module(yolo_features, sam2_features)\n",
    "        \n",
    "        # 3. 예시로, 가장 깊은 scale (채널 256인 feature map)을 detection head에 연결\n",
    "        final_feature = fused_features[-1]\n",
    "        predictions = self.detection_head(final_feature)\n",
    "        return predictions\n",
    "\n",
    "# ----------------- IPython Notebook에서 실행 예제 -----------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 재현성을 위한 랜덤 시드 설정\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # 1. Dummy YOLO backbone과 detection head 생성\n",
    "    yolo_backbone = DummyYOLOBackbone()\n",
    "    detection_head = DummyYOLODetectionHead()\n",
    "    \n",
    "    # 2. Fusion configuration: 각 scale별 (SAM2 채널, YOLO 채널)\n",
    "    # 질문에서 주신 feature map 정보에 따라 설정\n",
    "    fusion_configs = [(32, 32), (64, 64), (256, 256)]\n",
    "    \n",
    "    # 3. Fusion 모듈 초기화 (fusion_method는 'concat' 선택)\n",
    "    fusion_module = YOLOSAM2Fusion(fusion_configs, fusion_method='concat')\n",
    "    \n",
    "    # 4. YOLO 모델과 Fusion 모듈을 통합한 모델 생성\n",
    "    model = YOLOWithFusion(fusion_module, yolo_backbone, detection_head)\n",
    "    \n",
    "    # 5. Dummy 입력 이미지 생성 (예: 배치 크기 1, 3채널, 128x128 해상도)\n",
    "    dummy_input = torch.randn(1, 3, 128, 128)\n",
    "    \n",
    "    # 6. SAM2에서 추출한 backbone_fpn feature map 생성 (각 scale별 dummy 데이터)\n",
    "    sam2_feature0 = torch.randn(1, 32, 128, 128)   # Scale 0\n",
    "    sam2_feature1 = torch.randn(1, 64, 64, 64)      # Scale 1\n",
    "    sam2_feature2 = torch.randn(1, 256, 32, 32)     # Scale 2\n",
    "    sam2_features = [sam2_feature0, sam2_feature1, sam2_feature2]\n",
    "    \n",
    "    # 7. 모델 forward pass 수행 (학습/추론 단계에서 사용)\n",
    "    predictions = model(dummy_input, sam2_features)\n",
    "    \n",
    "    # 8. detection head의 예측 결과 출력\n",
    "    print(\"Predictions shape:\", predictions.shape)\n",
    "    # 예시: [1, 10, 32, 32] (batch, channel, height, width)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov11_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
